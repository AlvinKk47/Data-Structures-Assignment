Data Structures and Algorithms Group 7  - Research Document
Student Information
1.Alvin Kiprop-BSCCS/2025/52160
2.Eddy Munyua-BSCCS/2025/47991
3.Maxwell Munene-BSCCS/2025/51289
4.Vincent Kapkoyo-BSCCS/2025/51583
5.Keith Kyule-BSCCS/2025/49920
6.Enoch Onkoba-BSCCS/2025/55142
7.Eton Mutugi -BSCCS/2025/47559
8.Walcott Isaac-BSCCS/2025/48040
9.
10.




Data Structures and Algorithms - Research Document
Student Information
Name: [Your Name]

Student ID: [Your ID]

Group: [Group Name/Number]

Date: February 16, 2026

TASK 1.2: Applications of Data Structures
1. Arrays
Applications and Where They Are Used:

Student Grade Management System

Stores marks of students in multiple subjects

Why Arrays: Fast random access using index (O(1)), easy to calculate totals/averages

Image Processing

Digital images are stored as 2D arrays of pixels

Why Arrays: Natural representation of grid structure, efficient for filter operations

Game Development

Chess boards, tic-tac-toe, maze games

Why Arrays: Grid-based representation, quick access to any cell

Scientific Computing

Matrix operations, physics simulations

Why Arrays: Mathematical operations are optimized for array structures

Memory Management

Operating systems use arrays for memory tables

Why Arrays: Contiguous memory allocation, cache-friendly

Why Arrays Are Used:

Constant time access - Any element can be accessed directly using index (O(1))

Memory efficiency - No overhead for pointers (unlike linked lists)

Cache locality - Elements stored contiguously, better CPU cache performance

Simple implementation - Easy to understand and use

Multi-dimensional support - Can represent matrices and grids naturally

2. Linked Lists
Applications and Where They Are Used:

Music Player Playlists

Spotify, Apple Music playlists with next/previous functionality

Why Linked Lists: Dynamic size, easy insertion/deletion of songs

Web Browser History

Back/forward navigation in Chrome, Firefox

Why Linked Lists: Natural navigation between pages, memory efficient

Image Viewer

Slideshow applications with next/previous controls

Why Linked Lists: Easy to navigate between images

Operating Systems

Process scheduling, memory management

Why Linked Lists: Dynamic process creation/termination

Undo Functionality

Photoshop, Word - undo/redo operations

Why Linked Lists: Can traverse forward/backward through changes

Why Linked Lists Are Used:

Dynamic size - Can grow or shrink during runtime

Efficient insertion/deletion - O(1) at beginning, no shifting needed

Memory efficient - Only allocates memory for nodes needed

No memory waste - Unlike arrays with fixed size

Flexible - Can be singly, doubly, or circular as needed

3. Stacks
Applications and Where They Are Used:

Undo/Redo in Editors

Microsoft Word, Photoshop, VS Code

Why Stacks: LIFO nature matches undo operations (last action undone first)

Web Browser Back Button

Chrome, Firefox back navigation

Why Stacks: Stores visited URLs, last visited comes first when pressing back

Function Call Management

All programming languages use call stack

Why Stacks: Tracks function calls, returns to previous function after completion

Expression Evaluation

Calculator apps, compilers

Why Stacks: Evaluates mathematical expressions with operators

Syntax Parsing

Compilers check balanced parentheses, brackets

Why Stacks: Ensures proper nesting in code

Why Stacks Are Used:

LIFO principle - Matches many real-world scenarios

Simple operations - Push and pop are O(1)

Natural recursion - Recursive functions use the call stack

Memory efficient - Only stores what's needed

Backtracking - Easy to go back to previous state

4. Queues
Applications and Where They Are Used:

Printer Spooling

Windows/macOS print manager

Why Queues: First document sent prints first (FIFO)

Customer Service

Bank teller systems, call centers

Why Queues: First come, first served

Message Queues

WhatsApp, Slack, Messenger

Why Queues: Messages delivered in order sent

CPU Scheduling

Operating system process management

Why Queues: Fair allocation of CPU time

Keyboard Buffer

Typing on computer

Why Queues: Keys processed in order pressed

Why Queues Are Used:

FIFO principle - Fair processing order

Asynchronous processing - Can queue requests while processing others

Load balancing - Distributes work evenly

Buffering - Smooths out peak demands

Order preservation - Maintains sequence of events

5. Trees
Applications and Where They Are Used:

File System

Windows Explorer, macOS Finder

Why Trees: Hierarchical folder structure (parent-child)

HTML DOM

All web browsers parse HTML as tree

Why Trees: Document structure with nested elements

Database Indexing

MySQL, PostgreSQL use B-Trees

Why Trees: Fast searching (O(log n)) for millions of records

Network Routing

Routers use tree algorithms

Why Trees: Efficient path finding in networks

AI Decision Making

Game AI, machine learning

Why Trees: Decision trees for choosing actions

Why Trees Are Used:

Hierarchical data - Natural representation of parent-child relationships

Fast searching - Balanced trees achieve O(log n) search time

Sorted data - Binary Search Trees maintain sorted order

Efficient insertion/deletion - Better than arrays for dynamic data

Range queries - Can find all elements in a range efficiently

6. Graphs
Applications and Where They Are Used:

Google Maps

Navigation, shortest path

Why Graphs: Cities as vertices, roads as edges

Social Networks

Facebook, LinkedIn connections

Why Graphs: Users as vertices, friendships as edges

Network Routing

Internet packet routing

Why Graphs: Routers as vertices, connections as edges

Airline Networks

Flight connections between cities

Why Graphs: Airports as vertices, flights as edges

Recommendation Systems

Amazon, Netflix suggestions

Why Graphs: User-item relationships as graph

Why Graphs Are Used:

Complex relationships - Can represent many-to-many connections

Path finding - Algorithms exist for shortest/optimal paths

Network analysis - Can find important nodes, communities

Flexible structure - Directed, undirected, weighted edges

Real-world modeling - Many systems are naturally graph-based

TASK 1.3: Real-World Examples with Algorithms
Example 1: Google Maps Navigation
Data Structure Used: Graph
Algorithm Used: Dijkstra's Shortest Path Algorithm

How It Works:
Cities and locations become vertices in the graph. Roads and highways become edges connecting these vertices. Distance and travel time are assigned as weights to the edges. Dijkstra's algorithm then finds the shortest path from the source to the destination by always exploring the nearest unvisited vertex first. Real-time traffic data dynamically updates the edge weights to provide the fastest route considering current conditions.

Why This Combination?
Graphs naturally represent road networks with intersections and roads. Dijkstra's algorithm guarantees finding the shortest path and can handle weighted edges for distance, time, and traffic conditions. It remains efficient even for large-scale maps with millions of locations and supports additional features like alternate routes and waypoints.

Code Representation (Conceptual):

c
// Graph with weighted edges
struct Road {
    int destination;
    int distance;
    int trafficTime;
};

// Dijkstra's algorithm finds shortest path
void findShortestPath(Graph* map, int start, int end) {
    // Priority queue ensures we always process nearest vertex first
    // Returns optimal route considering distance/time
}
Example 2: Music Player Playlist (Spotify)
Data Structure Used: Doubly Linked List
Algorithm Used: Traversal Algorithms

How It Works:
Each song in the playlist is represented as a node in a doubly linked list. Each node contains the song data and two pointers: a next pointer to the following song and a previous pointer to the preceding song. A current pointer tracks the song currently playing. When the user clicks next, the player follows the next pointer. When they click previous, it follows the previous pointer. For repeat functionality, the last node's next pointer connects back to the first node, creating a circular list.

Why This Combination?
The dynamic size allows users to add or remove songs at any time without performance issues. Insertion and deletion operations are O(1) because no shifting of elements is required, unlike arrays. Navigation between songs is constant time O(1) in both directions. Memory usage is efficient because only the songs that exist in the playlist are stored. The structure easily supports additional features like shuffle modes and repeat functionality.

Code Representation (Conceptual):

c
struct Song {
    char title[100];
    char artist[50];
    struct Song* next;
    struct Song* prev;
};

void playNext(struct Song* current) {
    return current->next;  // O(1) operation
}
Example 3: ATM/Cash Counter System
Data Structure Used: Queue
Algorithm Used: FIFO (First In First Out) Processing

How It Works:
Customers arrive at the ATM and join the queue by being added to the rear (enqueue operation). The ATM always serves the customer at the front of the queue (dequeue operation). New customers must join at the end of the queue. This process continues until the queue becomes empty. Each customer is served strictly in the order they arrived, ensuring fairness.

Why This Combination?
The FIFO principle ensures fair handling where no one can skip ahead in line, which prevents disputes. The system is simple to implement and easy for customers to understand. Both enqueue and dequeue operations are O(1), making the system efficient even during peak hours. The queue can also track additional information like wait times and queue length for performance monitoring.

Code Representation (Conceptual):

c
struct Queue {
    int customerIDs[100];
    int front, rear;
};

void serveCustomer(Queue* atm) {
    int customer = dequeue(atm);  // Served now
    // Customer who arrived first gets served first
}
Example 4: Undo Feature in Text Editor (Microsoft Word)
Data Structure Used: Stack
Algorithm Used: Push/Pop Operations

How It Works:
Every action the user performs, such as typing characters, deleting text, or applying formatting, is represented as an action object and pushed onto a stack. When the user triggers an undo command, the most recent action is popped from the stack and reversed. A separate redo stack stores actions that were undone, allowing the user to redo them if needed. The stack can support multiple undo levels up to a configurable depth. The stack is typically cleared when the file is saved or closed.

Why This Combination?
The LIFO (Last In First Out) nature of a stack perfectly matches the expected behavior of undo operations, where the last action performed should be the first one undone. Push and pop operations are both O(1), ensuring that undo/redo actions are instantaneous regardless of stack size. Memory usage is proportional only to the number of actions performed, not the document size. The stack structure naturally supports sequential operations and can be easily implemented with multiple undo levels.

Code Representation (Conceptual):

c
struct Action {
    char type[10];  // "insert", "delete", "format"
    char text[100];
    int position;
};

void undo(Stack* actionStack) {
    Action lastAction = pop(actionStack);
    // Reverse the last action
}
Example 5: File System Hierarchy (Windows Explorer)
Data Structure Used: Tree
Algorithm Used: Depth-First Search (DFS) Traversal

How It Works:
The file system is organized as a tree structure. The root directory, such as C:, serves as the root node. Folders are internal nodes that can have multiple child nodes. Files are leaf nodes that cannot have children. Each node stores metadata like name, size, creation date, and permissions. Path names like C:\Users\Documents\file.txt represent the traversal path from the root to that node. When searching for files, a Depth-First Search traversal explores each branch completely before moving to the next, which is efficient for hierarchical data.

Why This Combination?
The tree structure provides a natural and intuitive representation of hierarchical file organization that users understand. Navigation commands like cd (change directory) simply traverse the tree to the appropriate node. Searching operations are efficient using tree traversal algorithms. The parent-child relationships clearly represent containment and organization. The structure supports unlimited nesting depth, allowing users to organize files in whatever way they prefer.

Code Representation (Conceptual):

c
struct FileNode {
    char name[256];
    int isDirectory;
    struct FileNode* firstChild;
    struct FileNode* nextSibling;
};

void listAllFiles(FileNode* folder) {
    // DFS traversal to show all contents
}
Example 6: Social Network Connections (Facebook)
Data Structure Used: Graph
Algorithm Used: Breadth-First Search (BFS)

How It Works:
In a social network like Facebook, each user is represented as a vertex in a graph. Friendship connections between users are represented as undirected edges connecting these vertices. When generating friend suggestions, a Breadth-First Search is performed starting from the user to find friends-of-friends within a certain depth. The degrees of separation between any two users can be calculated by the number of BFS levels needed to connect them. Communities and clusters can be detected using various graph algorithms that analyze connection patterns.

Why This Combination?
Graphs provide the most natural and accurate representation of social connections where relationships can be complex and many-to-many. BFS is particularly effective for finding the shortest path between users, which is exactly what "degrees of separation" represents. The algorithm can efficiently detect mutual friends and suggest new connections. The structure scales to billions of users when implemented with appropriate optimizations. Graph algorithms support additional features like community detection, influence analysis, and content recommendation.

Code Representation (Conceptual):

c
struct User {
    int id;
    char name[100];
    struct Friend* friends;  // Adjacency list
};

void suggestFriends(User* person) {
    // BFS to find friends-of-friends not already connected
}
TASK 1.4: How Data Structures Work Within Systems
1. Operating Systems
Process Scheduling

Operating systems use various data structures to manage process scheduling. The ready queue, which holds processes waiting for CPU time, is implemented as a queue data structure. New processes are added to the rear of the queue, and the scheduler selects processes from the front for execution, following the FIFO principle. For round-robin scheduling, a circular queue is used so that after a process uses its time slice, it goes back to the end of the queue to wait for another turn.

Priority queues, typically implemented using heap data structures, are used for priority-based scheduling. Higher priority processes are placed ahead of lower priority ones regardless of arrival time. This is essential for real-time operating systems where certain tasks must meet strict timing requirements.

Memory Management

Memory management relies heavily on linked lists. The free list, which tracks available memory blocks, is implemented as a linked list where each node represents a free memory region. When a program requests memory using malloc(), the system traverses this list to find a suitable block, removes it from the free list, and returns it to the program. When memory is freed using free(), the block is added back to the free list, potentially merging with adjacent free blocks.

Virtual memory systems use tree structures for page tables. Multi-level page tables are essentially trees that map virtual addresses to physical memory addresses. This hierarchical approach saves memory because only the levels that are actually needed are allocated, rather than having a huge single-level table.

The stack is fundamental to program execution. Each thread has its own call stack that stores local variables, function parameters, and return addresses. When a function is called, a new stack frame is pushed. When it returns, the frame is popped, restoring the previous execution context.

File Systems

File systems organize data using tree structures. The root directory sits at the top, with subdirectories branching out as internal nodes and files as leaf nodes. This hierarchical organization makes navigation intuitive through path names that represent paths from the root to the desired file.

Hard links and symbolic links create graph-like structures within the file system. Multiple directory entries can point to the same file data, creating a directed graph rather than a strict tree. Reference counting ensures that file data is only deleted when all references to it are removed.

The File Allocation Table (FAT) uses linked lists to track which disk blocks belong to which files. Each file's entry points to its first block, which contains a pointer to the next block, and so on, forming a linked list of blocks. This handles file fragmentation efficiently.

2. Database Systems
Indexing Structures

B-Trees and B+Trees are the most common indexing structures in database systems. MySQL, PostgreSQL, Oracle, and virtually all relational databases use these tree structures for indexing. They provide O(log n) time complexity for search, insert, and delete operations, which remains efficient even with millions of records. The trees are self-balancing, ensuring consistent performance. B+Trees are particularly good for range queries because all leaf nodes are linked together, allowing efficient traversal of sequential values.

Hash tables are used for hash indexes, providing O(1) time complexity for equality searches. They are ideal for primary key lookups where you need to find a specific record by its exact value. However, hash indexes cannot efficiently handle range queries or partial matches.

Bitmap indexes are used for columns with low cardinality, such as gender or status fields. They represent each distinct value as a bitmap where each bit indicates whether a row has that value. Bitmap indexes are extremely fast for boolean operations like AND, OR, and NOT, making them useful for data warehouse queries that combine multiple conditions.

Query Processing

When a SQL query is submitted, the database first builds a parse tree that represents the grammatical structure of the query. This tree shows how tables, columns, conditions, and joins relate to each other according to SQL syntax rules.

The query optimizer then transforms this parse tree into an execution plan, which can be represented as a graph. The graph shows the sequence of operations, join methods, and access paths that will be used to execute the query. The optimizer explores different execution plan alternatives and chooses the one with the lowest estimated cost.

During query execution, heap data structures are used for various operations. Sorting may use heap sort, hash joins build hash tables in memory, and temporary result sets may be stored in heap structures before being returned to the client.

Transaction Management

Transaction management uses multiple data structures to ensure ACID properties. Nested transactions and savepoints are managed using a stack structure, where each savepoint is pushed onto a stack and can be rolled back to by popping.

Transaction logs use queue structures for write-ahead logging. Before any change is applied to the database, it is written to the log queue. This ensures that even if the system crashes, the log can be replayed to recover committed transactions.

Undo and redo logs are often implemented as linked lists, tracking changes in sequence. The undo log allows rolling back uncommitted transactions, while the redo log allows reapplying committed transactions after a crash.

3. Compiler Design
Lexical Analysis

During lexical analysis, the compiler uses an array-based symbol table to store identifiers, keywords, and literals found in the source code. This table allows fast lookup to check if an identifier has been seen before and to store associated information like its type and scope.

The tokens produced by lexical analysis are typically stored in a linked list. This allows the parser to consume tokens sequentially while providing flexibility in lookahead and backtracking if needed.

Syntax Analysis

The parser builds a parse tree or Abstract Syntax Tree (AST) that represents the grammatical structure of the source code. Each node in the tree corresponds to a construct in the programming language, such as an if statement, a while loop, or an expression. The AST is used for subsequent phases including semantic analysis and intermediate code generation.

LR parsers use a stack during parsing. The stack holds grammar symbols and states, and the parser performs shift and reduce operations by pushing and popping from this stack. This stack-based approach is efficient and can handle a wide range of grammars.

Code Generation

The control flow graph represents the flow of control through a program. Basic blocks are nodes in the graph, and jumps and branches are edges connecting them. This representation is essential for optimizations like dead code elimination and for generating efficient machine code.

Register allocation uses stack structures to manage which variables are kept in registers versus spilled to memory. When too many variables are live simultaneously, some must be temporarily stored on the stack and reloaded when needed.

Instruction scheduling for pipelined processors uses queues to reorder instructions while respecting data dependencies. Instructions are queued and then issued in an order that minimizes pipeline stalls.

4. Network Systems
Routing

Network topology is represented as a graph where routers are vertices and network links are edges. Routing protocols like OSPF and BGP run graph algorithms to find optimal paths through the network. When a link fails, these algorithms recompute paths using the updated graph.

Routing tables are typically implemented as fast lookup tables, often using specialized data structures like Patricia tries or hash tables. These tables map destination networks to next-hop addresses and must support millions of lookups per second.

Packet queues in routers are critical for managing congestion. When packets arrive faster than they can be forwarded, they are stored in queues. Different queues may have different priorities for Quality of Service, and queue management algorithms decide which packets to drop when the queue fills up.

Protocol Implementation

Network protocols use queues extensively for buffering. TCP uses send and receive windows implemented as queues. The send queue holds packets that have been sent but not yet acknowledged, allowing retransmission if needed. The receive queue holds packets that have arrived but not yet been delivered to the application, handling out-of-order delivery by reordering packets.

The protocol stack itself follows a stack structure, with each layer adding its own headers to packets. When sending data, it flows down the stack, with each layer pushing its header. When receiving, it flows up the stack, with each layer popping its header.

The Domain Name System (DNS) uses a tree hierarchy. The root servers sit at the top, followed by top-level domains like .com, .org, and .net, then second-level domains, and so on down to individual hostnames. This tree structure enables delegation and distributed management.

5. Web Browsers
DOM Management

The Document Object Model (DOM) is a tree structure that represents the HTML document. Each HTML element becomes a node in the tree, with parent-child relationships reflecting the nesting of elements. JavaScript can traverse, modify, and manipulate this tree to create dynamic web pages. CSS inheritance also follows this tree structure, with styles propagating from parent to child nodes.

Events in a web browser are managed using an event queue. When the user clicks, moves the mouse, or presses a key, an event is added to the queue. The browser processes events in order, calling the appropriate JavaScript event handlers. This asynchronous model ensures that the interface remains responsive even while processing complex operations.

Browser history uses a stack to enable back and forward navigation. When the user visits a new page, the URL is pushed onto the history stack. Clicking the back button pops the current URL and reveals the previous one. Forward navigation uses a separate stack for undone actions.

Rendering Engine

The rendering engine builds a render tree from the DOM and CSS information. This tree contains only the visual elements that will actually be displayed, excluding hidden elements. Each node in the render tree knows its position, size, and visual properties. The layout phase calculates exact positions for all nodes, and the painting phase traverses the tree to draw each node on the screen.

Animation frames are managed using a queue. The browser aims to display 60 frames per second for smooth animation. Each frame's rendering tasks are queued and processed in order, with careful timing to maintain consistent frame rates.

Caching

Browser caches use hash tables for fast lookup of cached resources. When the browser requests a URL, it hashes the URL and checks the cache table in O(1) time to see if the resource is already available locally.

Cache eviction policies like LRU (Least Recently Used) are often implemented with linked lists. Each cached item is a node in a linked list, and whenever an item is accessed, it moves to the front of the list. When the cache fills up, items are evicted from the back of the list (the least recently used items).

6. Artificial Intelligence
Search Algorithms

State space search in AI uses graph structures extensively. Problem states become vertices, and actions that transition between states become edges. Solving a problem means finding a path from the initial state to a goal state. This graph representation works for everything from puzzle solving to game playing to planning problems.

Depth-First Search (DFS) uses a stack to implement its exploration strategy. The algorithm pushes states onto a stack as it explores deeper, and when it reaches a dead end, it pops back to the previous state. This approach is memory-efficient because it only needs to store the current path.

Breadth-First Search (BFS) uses a queue to explore level by level. It guarantees finding the shortest path in unweighted graphs but requires more memory because it must store all nodes at the current level.

Machine Learning

Feature vectors are implemented as arrays, which are fundamental to machine learning. Each data point is represented as an array of numerical features. Matrix operations on these arrays form the basis of algorithms like linear regression, neural networks, and support vector machines. The efficiency of array operations directly impacts training and inference speed.

Decision trees are literally tree data structures. Each internal node tests a feature, each branch represents the outcome of the test, and each leaf node represents a prediction or class label. Random Forests combine multiple decision trees for improved accuracy.

Neural networks are directed graphs. Neurons are vertices, and connections with weights are edges. Information flows through the graph during forward propagation, and errors flow backward during backpropagation. The graph structure can be extremely complex with millions of connections.

Natural Language Processing

Parse trees represent the grammatical structure of sentences. Each node corresponds to a grammatical unit like a noun phrase or verb phrase, with child nodes representing the components. These trees are essential for understanding sentence meaning and for generating grammatically correct text.

Knowledge graphs represent relationships between entities. Google's Knowledge Graph, for example, contains billions of nodes representing real-world entities and trillions of edges representing relationships. This graph structure enables semantic search and question answering by traversing connections between concepts.

Conclusion
Understanding how data structures integrate with algorithms and work within systems is crucial for:

Building efficient applications - Choosing the right data structure directly impacts performance. An application using appropriate data structures will run faster and use fewer resources than one using poorly chosen structures.

Optimizing resource usage - Time and space complexity matter in real-world systems. Understanding these trade-offs helps developers make informed decisions about memory usage versus speed.

Solving complex problems - Real-world problems often require sophisticated combinations of data structures and algorithms. The examples above show how different domains combine structures in unique ways.

Making informed design decisions - Knowledge of data structures allows architects to choose the right approach for each component, leading to better overall system design.

Scaling systems - Proper data structure choices enable systems to handle growth in users, data, and complexity. Facebook's graph can scale to billions of users because it's built on fundamentally sound data structure principles.

The choice of data structure directly impacts:

Time complexity of operations - Whether an operation takes constant time, logarithmic time, or linear time depends entirely on the chosen data structure.

Memory usage of the application - Some structures are memory-efficient but slower; others are faster but use more memory. The right balance depends on the application's constraints.

Scalability of the system - As data grows, some structures degrade gracefully while others become unusable. Choosing scalable structures is essential for long-term success.

User experience and responsiveness - Faster operations mean better user experience. A search that takes milliseconds instead of seconds can make the difference between a good and a bad application.

Development complexity and maintenance - Some structures are simple to implement and maintain; others require careful coding. The choice affects development time and bug probability